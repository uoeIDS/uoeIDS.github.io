<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Ethics in Data Science - Algorithmic Bias</title>
    <meta charset="utf-8" />
    <meta name="author" content="University of Edinburgh" />
    <script src="libs/header-attrs-2.30/header-attrs.js"></script>
    <link href="libs/panelset-0.3.0/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.3.0/panelset.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Ethics in Data Science - Algorithmic Bias
]
.subtitle[
## <br><br> Introduction to Data Science
]
.author[
### University of Edinburgh
]
.date[
### <br> 2025/2026
]

---






class: middle
# Case Study: Amazon's hiring algorithm

---

## Amazon's experimental hiring algorithm

- Used AI to give job candidates scores ranging from one to five stars -- much like shoppers rate products on Amazon
- Amazon's system was not rating candidates for software developer jobs and other technical posts in a gender-neutral way; it taught itself that male candidates were preferable

.pull-left-wide[
&gt;Gender bias was not the only issue. Problems with the data that underpinned the models’ judgments meant that unqualified candidates were often recommended for all manner of jobs, the people said.
]

.footnote[
Jeffrey Dastin. [Amazon scraps secret AI recruiting tool that showed bias against women](https://reut.rs/2Od9fPr).  
Reuters. 10 Oct 2018.
]

---

## Where is the bias?

&lt;img src="img/modelling-process.PNG" width="60%" style="display: block; margin: auto;" /&gt;


---

## Modelling questions

.pull-left[

![](w07-L14_files/figure-html/unnamed-chunk-2-1.png)&lt;!-- --&gt;


]
.pull-right[

Fit accuracy: (residual sum of squares)
`\(\sum_{i=1}^n (y_i - \hat{y}_i)^2\)` 
* Model 1: 0.0517701
* Model 2: 0.0199961

.question[
Q1: Which model gives a better fit to the data?
]


]


---

## Specific vs Generalisable 

.pull-left[

![](w07-L14_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;

]
.pull-right[
![](w07-L14_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;
]

.question[
Q2: For which model are you more likely to trust the predictions at `\(x=0.16\)` and `\(x=0.63\)`
]




---


class: middle

# Algorithmic bias and race

---

## Criminal Sentencing

.center[
"There’s software used across the country to predict future criminals.  
And it’s biased against blacks".
]

&lt;img src="img/propublica-criminal-sentencing.png" width="60%" style="display: block; margin: auto;" /&gt;

.footnote[
.midi[
Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. [Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing). 23 May 2016. ProPublica.
]
]

---


## A tale of two convicts

.pull-left[
![](img/propublica-prater-broden-edit-1.png)
]

.pull-right[

Brisha Borden
* Was running late to pick up her child from school.
* Stole a child's bike, and was spotted by a neighbor.
* Brisha was arrested for the 1st time.

Vernon Prater
* Arrested after shoplifting $86.35 worth of tools.
* Previously convicted of armed robbery, served 5 years.


.question[Who is more likely to re-offend?]

&lt;!--![](img/propublica-prater-broden-2.png)--&gt;
]


---

## What the computer said?!

&lt;img src="img/propublica-prater-broden-edit-2.png" width="50%" style="display: block; margin: auto;" /&gt;


---

class: middle

&gt;“Although these measures were crafted with the best of intentions, I am concerned that they inadvertently undermine our efforts to ensure individualized and equal justice,” he said, adding, “they may exacerbate unwarranted and unjust disparities that are already far too common in our criminal justice system and in our society.”
&gt;  
&gt;Then U.S. Attorney General Eric Holder (2014)

---

## ProPublica analysis

### **Data:**

Risk scores assigned to more than 7,000 people arrested in Broward County, Florida, in 2013 and 2014 + whether they were charged with new crimes over the next two years

---

## ProPublica analysis

### **Results:**

- 20% of those predicted to commit violent crimes actually did
- Algorithm had higher accuracy (61%) when full range of crimes taken into account (e.g. misdemeanors)
&lt;img src="img/propublica-results.png" width="85%" /&gt;
- Algorithm was more likely to falsely flag African American defendants as future criminals, at almost twice the rate as White defendants
- White defendants were mislabeled as low risk more often than African American defendants



---

class: middle
# Recommendations - "The Algorithm"

---

## Netflix recommendation algorithm

How Netflix's Recommendations System Works - [Source](https://help.netflix.com/en/node/100639).
* Optionally 'jump start' with your own preferences
* Preferences will be superseded once you start watching titles
* Update to recommendations includes information from:
  - your interaction with Netflix (history, ratings, etc.)
  - other members with similar tastes/preferences
  - information about titles (year, performers, genre, category)
* Also account for other factors: time of day, device, attention duration, etc.
* "... using algorithms and complex systems to provide a personalized experience."
* "We take feedback from very visit ... and continually re-train our algorithms"

--

**Netflix: How did it know I was bi before I did?** [BBC News](https://www.bbc.co.uk/news/technology-66472938), 13 Aug 2023.

---

class: middle
# Understanding its purpose


---

## Chat-GPT


* ChatGPT is a language model

* Designed for generating human-like text in response to user input

* A powerful tool for automating text generation and answering a wide range of questions and prompts.

* Trained on a large corpus of text and can generate coherent and contextually relevant responses.

---

## Chat-GPT: About itself!

&lt;img src="img/chat-gpt-self.PNG" width="100%" style="display: block; margin: auto;" /&gt;

---

## Chat-GPT: Ethics in Data Science

&lt;img src="img/chat-gpt-ethics.PNG" width="100%" style="display: block; margin: auto;" /&gt;

---

## Chat-GPT: Another example

&lt;img src="img/chat-gpt-mean-err.PNG" width="100%" style="display: block; margin: auto;" /&gt;

--

... but it is wrong, the correct answer is 536.32!!!

---

## Case Study: Mata vs Avianca Airline

* Roberto Mata sues airline for injury from metal serving cart.
* Lawyers for Mr Mata submit a document citing many 'relevant' court decision for their case.
* Neither judge or airline's lawyers were familiar with cases and sought copies of case notes.
* Mr Mata lawyers replied stating that they cannot locate requested case notes.

--

The initial document was generated by Chat-GPT, which **fabricated the references!**
* Judge: "... Do you cite cases without reading them?"
* Lawyer: "No."
* Judge: "What cause your departure here?"
* Lawyer: "I thought Chat-GPT was a search engine."

Further information: [YouTube, Legal Eagle](https://www.youtube.com/watch?v=oqSYljRYDEM)


---

## Parting thoughts

- At some point during your data science learning journey you will learn tools that can be used unethically

- You might also be tempted to use your knowledge in a way that is ethically questionable either because of business goals or for the pursuit of further knowledge (or because your boss told you to do so)

.question[
How do you train yourself to make the right decisions (or reduce the likelihood of accidentally making the wrong decisions) at those points?
]

---

## Further reading

.panelset[

.panel[.panel-name[Machine Bias]


.pull-left[

&lt;img src="img/propublica-machine-bias.png" width="80%" style="display: block; margin: auto;" /&gt;
]
.pull-right[
[Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)  
&lt;br&gt;
by Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner
]

]


.panel[.panel-name[Ethics &amp; DS]

.pull-left[
&lt;img src="img/ethics-data-science.jpg" width="50%" style="display: block; margin: auto;" /&gt;
]
.pull-right[
[Ethics and Data Science](https://www.amazon.com/Ethics-Data-Science-Mike-Loukides-ebook/dp/B07GTC8ZN7)  
&lt;br&gt;
by Mike Loukides, Hilary Mason, DJ Patil  
(Free Kindle download)
]

]

.panel[.panel-name[Math Destruction]

.pull-left[
&lt;img src="img/weapons-of-math-destruction.jpg" width="50%" style="display: block; margin: auto;" /&gt;
]
.pull-right[
[Weapons of Math Destruction](https://www.penguin.co.uk/books/304/304513/weapons-of-math-destruction/9780141985411.html)  
How Big Data Increases Inequality and Threatens Democracy  
&lt;br&gt;
by Cathy O'Neil
]
]

.panel[.panel-name[Alg.s of Oppression]

.pull-left[
&lt;img src="img/algorithms-of-oppression.jpg" width="50%" style="display: block; margin: auto;" /&gt;
]
.pull-right[
[Algorithms of Oppression](https://nyupress.org/9781479837243/algorithms-of-oppression/)  
How Search Engines Reinforce Racism  
&lt;br&gt;
by Safiya Umoja Noble
]


]



.panel[.panel-name[AI]


.pull-left[

&lt;img src="img/alan-turing-institute.PNG" width="60%" style="display: block; margin: auto;" /&gt;
]
.pull-right[
The Alan Turing Institute

[Understanding artificial intlligence ethics and safety](https://www.turing.ac.uk/sites/default/files/2019-06/understanding_artificial_intelligence_ethics_and_safety.pdf)  
A guide for the responsible design and implementation of AI systems in the public sector
&lt;br&gt;
by David Leslie
]

]

]

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
  "ratio": "16:9",
  "highlightLines": true,
  "highlightStyle": "solarized-light",
  "countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
